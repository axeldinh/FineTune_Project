{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11719,"status":"ok","timestamp":1617919403076,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"_qHnO4Vasc1z"},"outputs":[],"source":["from utils import *\n","from utils_training import *\n","from utils_dataset import *\n","from utils_metrics import *"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11733,"status":"ok","timestamp":1617919403107,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"2aNInI3isqL4"},"outputs":[],"source":["# The Training is defined by the parameters below\r\n","\r\n","# A few rules:\r\n","# - The first metric will be the one used to decide whether to save the model or not\r\n","# - num_eval is the number of evaluation per epoch\r\n","# - The TRAIN_PATH dataset will be divided in a train and validation set (with split train_frac)\r\n","# - subsample_train/test_size is an integer\r\n","\r\n","hyperparameters = {\r\n","    'device': 'cuda' if torch.cuda.is_available() else 'cpu',       # device for training (should be GPU)\r\n","    'metrics_names': ['MatthewCorr', 'Accuracy', 'F1 Score'],       # Metrics on which to do the evaluations\r\n","    'num_eval': 10,                                                 # Number of evaluation per epoch\r\n","    'model_name': 'bert-base-cased',                                # Model to train (by default should be 'bert-base-cased')\r\n","    'seed': torch.randint(10000, size = (1,1)).squeeze(0).item(),   # Seed for training\r\n","    'dataset_name': 'CoLA',                                         # Name of the dataset ('CoLA', 'RTE', 'QNLI', 'SST-2')\r\n","    'batch_size': 8,                                                # Training batch size\r\n","    'lr': 5e-4,                                                     # Learning rate\r\n","    'TRAIN_PATH': 'data/CoLA/train.tsv',                            # Path to training set\r\n","    'TEST_PATH': 'data/CoLA/dev.tsv',                               # Path to validation set (will be our test set)\r\n","    'num_epochs': 20,                                               # Number of epochs\r\n","    'Finetuning': 'Init&BitFit',                                    # Type of Fine-Tuning ('Full', 'BitFit', 'LayerNorm', 'Random', 'Init&BitFit', 'InitBias&BitFit')\r\n","    'subsample_train_size': None,                                   # Number of training samples, if None all the samples are used\r\n","    'subsample_test_size': None,                                    # Number of test samples, if None all the samples are used\r\n","    'max_length': 512,                                              # Maximum length of a sample (should depend on the model, 512 by default)\r\n","    'train_frac': 0.8,                                              # train/validation split ratio\r\n","    'grad_masks': None,                                             # gradient masks for the random Fine-Tuning    \r\n","    'ratio_params': None,                                           # Ratio of parameters trained for random fine-tuning\r\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Full Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87182,"status":"ok","timestamp":1617919478586,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"1KO4Texl1M-p","outputId":"f7e60fa9-e18b-4d34-94dc-48d29be79c15"},"outputs":[],"source":["# Full finetuning for CoLA\n","\n","seeds = [5542, 3568, 6396, 5225, 3583, 6066, 6112, 8083, 4472, 6081]\n","hyperparameters['Finetuning'] = 'Full'\n","hyperparameters['lr'] = 3e-5\n","\n","for seed in seeds:\n","    hyperparameters['seed'] = seed\n","    training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# BitFit Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303429,"status":"ok","timestamp":1617919694853,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"BQKy7Ad8tHAB","outputId":"2388c20b-5068-4019-e162-3aedfefa884f"},"outputs":[],"source":["# BitFit finetuning\n","seeds = [5542, 3568, 6396, 5225, 3583, 6066, 6112, 8083, 4472, 6081]\n","hyperparameters['Finetuning'] = 'BitFit'\n","lrs = [1e-4, 5e-4, 1e-3]\n","\n","for lr in lrs:\n","  for seed in seeds:\n","      hyperparameters['seed'] = seed\n","      hyperparameters['lr'] = lr\n","      training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# LayerNorm Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525091,"status":"ok","timestamp":1617919916541,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"Uy9iOF3P_fOs","outputId":"62bb9f34-38d8-491b-ed63-3759ebbff476"},"outputs":[],"source":["# LayerNorm finetuning\n","seeds = [5542, 3568, 6396, 5225, 3583, 6066, 6112, 8083, 4472, 6081]\n","hyperparameters['Finetuning'] = 'LayerNorm'\n","lrs = [1e-4, 5e-4, 1e-3]\n","\n","for lr in lrs:\n","    for seed in seeds: \n","        hyperparameters['seed'] = seed\n","        hyperparameters['lr'] = lr\n","        training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# Low Data Regime Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Full Finetuning and changing train_size\r\n","seeds = [1854, 1717, 3509, 4761, 233, 4561, 5447, 8593, 5259, 5138]\r\n","train_sizes = [5000, 2500, 1000, 500, 100]\r\n","lrs = [3e-5]\r\n","hyperparameters['Finetuning'] = 'Full'\r\n","\r\n","for seed in seeds:\r\n","  for lr in lrs:\r\n","    for train_size in train_sizes:\r\n","      hyperparameters['seed'] = seed\r\n","      hyperparameters['lr'] = lr\r\n","      hyperparameters['subsample_train_size'] = train_size\r\n","      training(hyperparameters)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# BitFit Finetuning and changing train_size\r\n","seeds = [1854, 1717, 3509, 4761, 233, 4561, 5447, 8593, 5259, 5138]\r\n","train_sizes = [5000, 2500, 1000, 500, 100]\r\n","lrs = [1e-4, 5e-4, 1e-3]\r\n","hyperparameters['Finetuning'] = 'BitFit'\r\n","\r\n","for seed in seeds:\r\n","  for lr in lrs:\r\n","    for train_size in train_sizes:\r\n","      hyperparameters['seed'] = seed\r\n","      hyperparameters['lr'] = lr\r\n","      hyperparameters['subsample_train_size'] = train_size\r\n","      training(hyperparameters)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LayerNorm Finetuning and changing train_size\r\n","seeds = [1854, 1717, 3509, 4761, 233, 4561, 5447, 8593, 5259, 5138]\r\n","train_sizes = [5000, 2500, 1000, 500, 100]\r\n","lrs = [1e-4, 5e-4, 1e-3]\r\n","hyperparameters['Finetuning'] = 'LayerNorm'\r\n","\r\n","for seed in seeds:\r\n","  for lr in lrs:\r\n","    for train_size in train_sizes:\r\n","      hyperparameters['seed'] = seed\r\n","      hyperparameters['lr'] = lr\r\n","      hyperparameters['subsample_train_size'] = train_size\r\n","      training(hyperparameters)\r\n","\r\n","hyperparameters['subsample_train_size'] = None"]},{"cell_type":"markdown","metadata":{},"source":["# Random Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Finetuning\r\n","seeds = [4500, 6731, 1433, 4120,  943, 9217, 8121, 2816,  633, 5185]\r\n","lrs = [5e-4, 1e-3, 5e-3]\r\n","\r\n","hyperparameters['Finetuning'] = 'Random'\r\n","model_base = BertForSequenceClassification.from_pretrained(hyperparameters['model_name'])\r\n","hyperparameters['ratio_params'] = 0.001\r\n","\r\n","for lr in lrs:\r\n","    hyperparameters['lr'] = lr\r\n","    for seed in seeds:\r\n","        hyperparameters['seed'] = seed\r\n","        grad_masks = get_grad_mask(model_base, hyperparameters['ratio_params'])\r\n","        hyperparameters['grad_masks'] = grad_masks\r\n","        training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# Init+BitFit"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.0005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.01_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3568_lr0.01_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3583_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3583_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3583_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed3583_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed4472_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed4472_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed4472_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed4472_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.0005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.01_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5225_lr0.01_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.0005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.01_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5542_lr0.01_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.0001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.0005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.01_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.01_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.05_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.1_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.1_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.5_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr0.5_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr1e-05_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr1e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr1_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr1_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr5e-05_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed5710_lr5e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6066_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6066_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6066_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6066_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6081_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6081_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6081_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6081_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6112_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6112_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6112_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6112_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.0005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.01_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed6396_lr0.01_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed8083_lr0.001_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed8083_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Init_BitFit_bert-base-cased_CoLA_seed8083_lr0.005_epochs20:\n","\n","\n","Init_BitFit_bert-base-cased_CoLA_seed8083_lr0.005_epochs20 already trained\n","\n","\n"]}],"source":["# Reinitialize all parameters then BitFit\r\n","\r\n","# First we retrieve the different learning rates and seeds\r\n","\r\n","import os\r\n","\r\n","seeds = []\r\n","lrs = []\r\n","for name in os.listdir('ResultsTest/Models/CoLA'):\r\n","    if 'Init_BitFit' in name:\r\n","        seeds.append(int(name.split('_')[4].replace('seed','')))\r\n","        lrs.append(float(name.split('_')[5].replace('lr','')))\r\n","\r\n","for lr, seed in zip(lrs, seeds):\r\n","\r\n","    if lr == 1.: lr = int(lr)\r\n","    \r\n","    hyperparameters['lr'] = lr\r\n","    hyperparameters['seed'] = seed\r\n","    hyperparameters['Finetuning'] = 'Init&BitFit'\r\n","    \r\n","    training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# InitBias+BitFit Fine-Tuning"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5271_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed6789_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5892_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5078_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3581_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed3706_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed8757_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed5910_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed137_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_CoLA_seed7205_lr0.005_epochs20 already trained\n","\n","\n"]}],"source":["# InitBias&Bitfit finetuning for CoLA\n","seeds = [5271, 6789, 5892, 5078, 3581, 3706, 8757, 5910,  137, 7205]\n","lrs = [1e-4, 5e-4, 1e-3, 5e-3]\n","hyperparameters['Finetuning'] = 'InitBias&BitFit'\n","\n","for lr in lrs:\n","    for seed in seeds:\n","        hyperparameters['seed'] = seed\n","        hyperparameters['lr'] = lr\n","        training(hyperparameters)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CoLA.ipynb","provenance":[]},"interpreter":{"hash":"cdd16d5fc14acf61db435beefaed9190f2350bf41449cca35592c510838b9907"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}