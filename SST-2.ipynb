{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11719,"status":"ok","timestamp":1617919403076,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"_qHnO4Vasc1z"},"outputs":[],"source":["from utils import *\n","from utils_training import *\n","from utils_dataset import *\n","from utils_metrics import *"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11733,"status":"ok","timestamp":1617919403107,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"2aNInI3isqL4"},"outputs":[],"source":["# The Training is defined by the parameters below\r\n","\r\n","# A few rules:\r\n","# - The first metric will be the one used to decide whether to save the model or not\r\n","# - num_eval is the number of evaluation per epoch\r\n","# - The TRAIN_PATH dataset will be divided in a train and validation set (with split train_frac)\r\n","# - subsample_train/test_size is an integer\r\n","\r\n","hyperparameters = {\r\n","    'device': 'cuda' if torch.cuda.is_available() else 'cpu',       # device for training (should be GPU)\r\n","    'metrics_names': ['Accuracy', 'MatthewCorr', 'F1 Score'],       # Metrics on which to do the evaluations\r\n","    'num_eval': 10,                                                 # Number of evaluation per epoch\r\n","    'model_name': 'bert-base-cased',                                # Model to train (by default should be 'bert-base-cased')\r\n","    'seed': torch.randint(10000, size = (1,1)).squeeze(0).item(),   # Seed for training\r\n","    'dataset_name': 'SST-2',                                         # Name of the dataset ('CoLA', 'RTE', 'QNLI', 'SST-2')\r\n","    'batch_size': 8,                                                # Training batch size\r\n","    'lr': 5e-4,                                                     # Learning rate\r\n","    'TRAIN_PATH': 'data/SST-2/train.tsv',                            # Path to training set\r\n","    'TEST_PATH': 'data/SST-2/dev.tsv',                               # Path to validation set (will be our test set)\r\n","    'num_epochs': 20,                                               # Number of epochs\r\n","    'Finetuning': 'Full',                                    # Type of Fine-Tuning ('Full', 'BitFit', 'LayerNorm', 'Random', 'Init&BitFit', 'InitBias&BitFit')\r\n","    'subsample_train_size': None,                                   # Number of training samples, if None all the samples are used\r\n","    'subsample_test_size': None,                                    # Number of test samples, if None all the samples are used\r\n","    'max_length': 512,                                              # Maximum length of a sample (should depend on the model, 512 by default)\r\n","    'train_frac': 0.8,                                              # train/validation split ratio\r\n","    'grad_masks': None,                                             # gradient masks for the random Fine-Tuning    \r\n","    'ratio_params': None,                                           # Ratio of parameters trained for random fine-tuning\r\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Full Fine-Tuning"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87182,"status":"ok","timestamp":1617919478586,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"1KO4Texl1M-p","outputId":"f7e60fa9-e18b-4d34-94dc-48d29be79c15"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","Full_bert-base-cased_SST-2_seed2178_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_SST-2_seed2178_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_SST-2_seed3514_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_SST-2_seed3514_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_SST-2_seed770_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_SST-2_seed770_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_SST-2_seed4179_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_SST-2_seed4179_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_SST-2_seed3813_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_SST-2_seed3813_lr3e-05_epochs20 already trained\n","\n","\n"]}],"source":["# Full finetuning for SST-2\r\n","\r\n","seeds = [2178, 3514, 770, 4179, 3813]\r\n","hyperparameters['Finetuning'] = 'Full'\r\n","hyperparameters['lr'] = 3e-5\r\n","\r\n","for seed in seeds:\r\n","    hyperparameters['seed'] = seed\r\n","    training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# BitFit Fine-Tuning"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303429,"status":"ok","timestamp":1617919694853,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"BQKy7Ad8tHAB","outputId":"2388c20b-5068-4019-e162-3aedfefa884f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed2178_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed2178_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed3514_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed3514_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed770_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed770_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed4179_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed4179_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed3813_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed3813_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed2178_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed2178_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed3514_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed3514_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed770_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed770_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed4179_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed4179_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed3813_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed3813_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed2178_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed2178_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed3514_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed3514_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed770_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed770_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed4179_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed4179_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_SST-2_seed3813_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_SST-2_seed3813_lr0.001_epochs20 already trained\n","\n","\n"]}],"source":["# BitFit finetuning for SST-2\r\n","\r\n","seeds = [2178, 3514, 770, 4179, 3813]\r\n","hyperparameters['Finetuning'] = 'BitFit'\r\n","lrs = [1e-4, 5e-4, 1e-3]\r\n","\r\n","for lr in lrs:\r\n","  for seed in seeds:\r\n","      hyperparameters['seed'] = seed\r\n","      hyperparameters['lr'] = lr\r\n","      training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# LayerNorm Fine-Tuning"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525091,"status":"ok","timestamp":1617919916541,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"Uy9iOF3P_fOs","outputId":"62bb9f34-38d8-491b-ed63-3759ebbff476"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed2178_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed2178_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed3514_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed3514_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed770_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed770_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed4179_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed4179_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed3813_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed3813_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed2178_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed2178_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed3514_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed3514_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed770_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed770_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed4179_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed4179_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed3813_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed3813_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed2178_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed2178_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed3514_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed3514_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed770_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed770_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed4179_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed4179_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_SST-2_seed3813_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_SST-2_seed3813_lr0.001_epochs20 already trained\n","\n","\n"]}],"source":["# LayerNorm finetuning for SST-2\r\n","seeds = [2178, 3514, 770, 4179, 3813]\r\n","hyperparameters['Finetuning'] = 'LayerNorm'\r\n","lrs = [1e-4, 5e-4, 1e-3]\r\n","\r\n","for lr in lrs:\r\n","  for seed in seeds:\r\n","      hyperparameters['seed'] = seed\r\n","      hyperparameters['lr'] = lr\r\n","      training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# Random Fine-Tuning"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed2957_lr0.0005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed2957_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed741_lr0.0005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed741_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed7633_lr0.0005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed7633_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed8251_lr0.0005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed8251_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed1100_lr0.0005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed1100_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed2957_lr0.001_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed2957_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed741_lr0.001_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed741_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed7633_lr0.001_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed7633_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed8251_lr0.001_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed8251_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed1100_lr0.001_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed1100_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed2957_lr0.005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed2957_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed741_lr0.005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed741_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed7633_lr0.005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed7633_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed8251_lr0.005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed8251_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Random0.001_bert-base-cased_SST-2_seed1100_lr0.005_epochs20:\n","\n","\n","Random0.001_bert-base-cased_SST-2_seed1100_lr0.005_epochs20 already trained\n","\n","\n"]}],"source":["# Random Finetuning for SST-2\r\n","hyperparameters['Finetuning'] = 'Random'\r\n","hyperparameters['ratio_params'] = 0.001\r\n","\r\n","seeds = [2957,  741, 7633, 8251, 1100]\r\n","lrs = [5e-4, 1e-3, 5e-3]\r\n","model_base = BertForSequenceClassification.from_pretrained(hyperparameters['model_name'])\r\n","\r\n","for lr in lrs:\r\n","    for seed in seeds:\r\n","\r\n","      hyperparameters['lr'] = lr\r\n","      hyperparameters['seed'] = seed\r\n","      grad_masks = get_grad_mask(model_base, hyperparameters['ratio_params'])\r\n","      hyperparameters['grad_masks'] = grad_masks\r\n","\r\n","      training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# InitBias+BitFit Fine-Tuning"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.0001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.0005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.001_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5271_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed6789_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5892_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed5078_lr0.005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.005_epochs20:\n","\n","\n","InitBias_BitFit_bert-base-cased_SST-2_seed3581_lr0.005_epochs20 already trained\n","\n","\n"]}],"source":["# InitBias&Bitfit finetuning for CoLA\r\n","\r\n","hyperparameters['Finetuning'] = 'InitBias&BitFit'\r\n","\r\n","seeds = [5271, 6789, 5892, 5078, 3581]\r\n","lrs = [1e-4, 5e-4, 1e-3, 5e-3]\r\n","\r\n","\r\n","for lr in lrs:\r\n","    for seed in seeds:\r\n","        hyperparameters['seed'] = seed\r\n","        hyperparameters['lr'] = lr\r\n","        training(hyperparameters)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CoLA.ipynb","provenance":[]},"interpreter":{"hash":"cdd16d5fc14acf61db435beefaed9190f2350bf41449cca35592c510838b9907"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}