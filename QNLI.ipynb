{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":11719,"status":"ok","timestamp":1617919403076,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"_qHnO4Vasc1z"},"outputs":[],"source":["from utils import *\n","from utils_training import *\n","from utils_dataset import *\n","from utils_metrics import *"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":11733,"status":"ok","timestamp":1617919403107,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"2aNInI3isqL4"},"outputs":[],"source":["# The Training is defined by the parameters below\r\n","\r\n","# A few rules:\r\n","# - The first metric will be the one used to decide whether to save the model or not\r\n","# - num_eval is the number of evaluation per epoch\r\n","# - The TRAIN_PATH dataset will be divided in a train and validation set (with split train_frac)\r\n","# - subsample_train/test_size is an integer\r\n","\r\n","hyperparameters = {\r\n","    'device': 'cuda' if torch.cuda.is_available() else 'cpu',       # device for training (should be GPU)\r\n","    'metrics_names': ['Accuracy', 'MatthewCorr', 'F1 Score'],       # Metrics on which to do the evaluations\r\n","    'num_eval': 10,                                                 # Number of evaluation per epoch\r\n","    'model_name': 'bert-base-cased',                                # Model to train (by default should be 'bert-base-cased')\r\n","    'seed': torch.randint(10000, size = (1,1)).squeeze(0).item(),   # Seed for training\r\n","    'dataset_name': 'QNLI',                                         # Name of the dataset ('CoLA', 'RTE', 'QNLI', 'SST-2')\r\n","    'batch_size': 8,                                                # Training batch size\r\n","    'lr': 5e-4,                                                     # Learning rate\r\n","    'TRAIN_PATH': 'data/QNLI/train.tsv',                            # Path to training set\r\n","    'TEST_PATH': 'data/QNLI/dev.tsv',                               # Path to validation set (will be our test set)\r\n","    'num_epochs': 20,                                               # Number of epochs\r\n","    'Finetuning': 'Full',                                    # Type of Fine-Tuning ('Full', 'BitFit', 'LayerNorm', 'Random', 'Init&BitFit', 'InitBias&BitFit')\r\n","    'subsample_train_size': None,                                   # Number of training samples, if None all the samples are used\r\n","    'subsample_test_size': None,                                    # Number of test samples, if None all the samples are used\r\n","    'max_length': 512,                                              # Maximum length of a sample (should depend on the model, 512 by default)\r\n","    'train_frac': 0.8,                                              # train/validation split ratio\r\n","    'grad_masks': None,                                             # gradient masks for the random Fine-Tuning    \r\n","    'ratio_params': None,                                           # Ratio of parameters trained for random fine-tuning\r\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Full Fine-Tuning"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87182,"status":"ok","timestamp":1617919478586,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"1KO4Texl1M-p","outputId":"f7e60fa9-e18b-4d34-94dc-48d29be79c15"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","Full_bert-base-cased_QNLI_seed7200_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_QNLI_seed7200_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_QNLI_seed7516_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_QNLI_seed7516_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_QNLI_seed6665_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_QNLI_seed6665_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_QNLI_seed3575_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_QNLI_seed3575_lr3e-05_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","Full_bert-base-cased_QNLI_seed551_lr3e-05_epochs20:\n","\n","\n","Full_bert-base-cased_QNLI_seed551_lr3e-05_epochs20 already trained\n","\n","\n"]}],"source":["# Full finetuning for QNLI\r\n","\r\n","seeds = [7200, 7516, 6665, 3575, 551]\r\n","hyperparameters['Finetuning'] = 'Full'\r\n","hyperparameters['lr'] = 3e-5\r\n","\r\n","for seed in seeds:\r\n","    hyperparameters['seed'] = seed\r\n","    training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# BitFit Fine-Tuning"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303429,"status":"ok","timestamp":1617919694853,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"BQKy7Ad8tHAB","outputId":"2388c20b-5068-4019-e162-3aedfefa884f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed7200_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed7200_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed7516_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed7516_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed6665_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed6665_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed3575_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed3575_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed551_lr0.0001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed551_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed7200_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed7200_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed7516_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed7516_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed6665_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed6665_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed3575_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed3575_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed551_lr0.0005_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed551_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed7200_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed7200_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed7516_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed7516_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed6665_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed6665_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed3575_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed3575_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","BitFit_bert-base-cased_QNLI_seed551_lr0.001_epochs20:\n","\n","\n","BitFit_bert-base-cased_QNLI_seed551_lr0.001_epochs20 already trained\n","\n","\n"]}],"source":["# BitFit finetuning for QNLI\r\n","\r\n","seeds = [7200, 7516, 6665, 3575, 551]\r\n","hyperparameters['Finetuning'] = 'BitFit'\r\n","lrs = [1e-4, 5e-4, 1e-3]\r\n","\r\n","for lr in lrs:\r\n","  for seed  in seeds:\r\n","\r\n","    hyperparameters['seed'] = seed\r\n","    hyperparameters['lr'] = lr\r\n","    training(hyperparameters)"]},{"cell_type":"markdown","metadata":{},"source":["# LayerNorm Fine-Tuning"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525091,"status":"ok","timestamp":1617919916541,"user":{"displayName":"Axel Dinh Van Chi","photoUrl":"","userId":"14432571414133864942"},"user_tz":-120},"id":"Uy9iOF3P_fOs","outputId":"62bb9f34-38d8-491b-ed63-3759ebbff476"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed7200_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed7200_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed7516_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed7516_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed6665_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed6665_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed3575_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed3575_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed551_lr0.0001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed551_lr0.0001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed7200_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed7200_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed7516_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed7516_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed6665_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed6665_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed3575_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed3575_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed551_lr0.0005_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed551_lr0.0005_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed7200_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed7200_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed7516_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed7516_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed6665_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed6665_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed3575_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed3575_lr0.001_epochs20 already trained\n","\n","\n","\n","==================================================================\n","\n","LayerNorm_bert-base-cased_QNLI_seed551_lr0.001_epochs20:\n","\n","\n","LayerNorm_bert-base-cased_QNLI_seed551_lr0.001_epochs20 already trained\n","\n","\n"]}],"source":["# LayerNorm finetuning for QNLI\r\n","seeds = [7200, 7516, 6665, 3575, 551]\r\n","hyperparameters['Finetuning'] = 'LayerNorm'\r\n","lrs = [1e-4, 5e-4, 1e-3]\r\n","\r\n","for lr in lrs:\r\n","  for seed in seeds:\r\n","      hyperparameters['seed'] = seed\r\n","      hyperparameters['lr'] = lr\r\n","      training(hyperparameters)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CoLA.ipynb","provenance":[]},"interpreter":{"hash":"cdd16d5fc14acf61db435beefaed9190f2350bf41449cca35592c510838b9907"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}